{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "from io import StringIO\n",
    "import re\n",
    "import numpy as np\n",
    "import requests\n",
    "from typing import Any, List, Mapping, Optional\n",
    "from langchain_core.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from typing import Optional, Sequence, Union, TypeVar, List, Dict, Any, Tuple, cast\n",
    "from langchain.prompts.example_selector.ngram_overlap import NGramOverlapExampleSelector\n",
    "from langchain.output_parsers.enum import EnumOutputParser\n",
    "from enum import Enum\n",
    "from gbnf_compiler import *\n",
    "from random import sample \n",
    "\n",
    "\n",
    "#read in grammar file\n",
    "grammar = \"\"\n",
    "with open('json.gbnf', 'r') as file:\n",
    "    grammar = file.read()\n",
    "\n",
    "\n",
    "#llm connector for Palmetto Cluster (llama.cpp ./server)\n",
    "class CustomLLM(LLM):\n",
    "    n: int\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "        \n",
    "        payload = {\n",
    "            \"prompt\": prompt,\n",
    "            \"temperature\": 0.15, \n",
    "            \"cache_prompt\": True,\n",
    "            \"n_predict\": self.n,\n",
    "            \"grammar\": grammar\n",
    "        }\n",
    "        response = requests.post(\"http://localhost:8080/completion\", json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json().get(\"content\", \"\")\n",
    "        else:\n",
    "            raise Exception(f\"Error from llama.cpp server: {response.text}\")\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {\"n\": self.n}\n",
    "        \n",
    "#create langchain llm instance\n",
    "llm = CustomLLM(n=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            COMMENT1 Expectations Met  \\\n",
      "0  Very through, no short cuts!  It was if we wer...              Yes   \n",
      "1                                         No comment          Unknown   \n",
      "2                                               Poor               No   \n",
      "3   The nurses were unbelievably helpful and caring.              Yes   \n",
      "4  i should have been allowed to come back with m...               No   \n",
      "\n",
      "  Trust in Staff Feeling of Safety Positive Experience    Dirty  \\\n",
      "0        Unknown           Unknown                 Yes  Unknown   \n",
      "1        Unknown           Unknown             Unknown  Unknown   \n",
      "2        Unknown           Unknown             Unknown  Unknown   \n",
      "3            Yes           Unknown                 Yes  Unknown   \n",
      "4        Unknown           Unknown             Unknown  Unknown   \n",
      "\n",
      "  Risks/Challenges Actions/Strategies      Facilitators  Visit Rating  \n",
      "0          unknown            unknown  resources_caring           NaN  \n",
      "1          unknown            unknown           unknown           NaN  \n",
      "2          unknown            unknown           unknown           NaN  \n",
      "3          unknown            unknown           unknown           NaN  \n",
      "4          unknown            unknown           unknown           NaN  \n"
     ]
    }
   ],
   "source": [
    "#prepare few-shot file\n",
    "few_shot_examples = pd.read_csv('fixed.csv')\n",
    "data_column = 'COMMENT1'\n",
    "data_column_2 = 'COMMENT1'\n",
    "\n",
    "headers = []\n",
    "for col in few_shot_examples.columns:\n",
    "    if (col != data_column_2):\n",
    "        headers.append(col)\n",
    "\n",
    "# parse dataframe into examples using grammar format\n",
    "examples_list = []\n",
    "for index, row in few_shot_examples.iterrows():\n",
    "    ex= {'Comment': row[data_column] }        \n",
    "    ex['Data'] = ('\\n'.join([f'{col}: {row[col]}' for col in headers]))\n",
    "    examples_list.append(ex)\n",
    "\n",
    "examples_list = sample(examples_list,30)\n",
    "print(few_shot_examples.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframe\n",
    "new_data = pd.read_csv('ptinfo.csv')\n",
    "new_data = new_data[['COMMENT1']]\n",
    "\n",
    "\n",
    "#template config\n",
    "qtemp = \"<|start_header_id|>user<|end_header_id|>Patient Feedback: {Comment}\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n{Data}<|eot_id|>\"\n",
    "\n",
    "labels_s = headers[:]\n",
    "labels_s.append(\"Comment\")\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=['Comment','Data'], template=qtemp\n",
    ")\n",
    "\n",
    "sys_prompt = '''<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "# Task:\n",
    "The comments that you are given are a patient describing their visit at a hospital.\n",
    "Label the patient feedback data based on the different fields.\n",
    "If there is no context for the field, return 'unknown' for the field.\n",
    "Because the comments are anonymized, [person_name] represents an identify name that has been anonymized.\n",
    "If the comment is '(BLANK)', '(INAUDIBLE)' or '(unreadable)', just label 'unknown' for all categories unless you can extract meaningful statements.\n",
    "If the comment appears incomplete or a fragment, just label 'unknown' for all categories unless you can extract meaningful statements.\n",
    "Consider the sentiment of the patient feedback before labeling.\n",
    "Return only the label structure as follows:\n",
    "\n",
    "# Output Structure:\n",
    "Expectations Met: [Label]\n",
    "Trust in Staff: [Label]\n",
    "Feeling of Safety: [Label]\n",
    "Positive Experience: [Label]\n",
    "Dirty: [Label]\n",
    "Risks/Challenges: [Label]\n",
    "Actions/Strategies: [Label]\n",
    "Facilitators: [Label]\n",
    "Visit Rating: [1-5]\n",
    "\n",
    "\n",
    "# Output Labels:\n",
    "Expectations Met:\n",
    "This field evaluates whether the patient's expectations regarding their visit, treatment, or service were met. Possible labels:\n",
    "yes: The patient's expectations were met. Make sure that the patient is not being sarcastic, as that means that their expectations probably have not been met.\n",
    "no: The patient's expectations were not met.\n",
    "unknown: It is unclear or not recorded whether the patient's expectations were met.\n",
    "\n",
    "Trust in Staff:\n",
    "This measures the patient's level of trust in the medical staff's competence and intentions. Possible labels:\n",
    "yes: The patient trusted the staff.\n",
    "no: The patient did not trust the staff.\n",
    "unknown: It is unclear or not recorded whether the patient trusted the staff.\n",
    "\n",
    "Feeling of Safety:\n",
    "This field assesses the patient's perception of safety during their stay or visit. Possible labels:\n",
    "yes: The patient felt safe.\n",
    "no: The patient did not feel safe.\n",
    "unknown: It is unclear or not recorded whether the patient felt safe.\n",
    "\n",
    "Positive Experience:\n",
    "This field indicates whether the overall experience of the patient was positive. Possible labels:\n",
    "yes: The patient had a positive experience.\n",
    "no: The patient had a negative experience.\n",
    "unknown: It is unclear or not recorded what the patient's overall experience was.\n",
    "\n",
    "Dirty:\n",
    "Label as 'unknown' if no Possible labels:\n",
    "yes: Hospital is specifically mentioned as being dirty.\n",
    "no: Hospital is specifically mentioned as being clean.\n",
    "unknown: Nothing about cleanliness is mentioned. Default.\n",
    "\n",
    "Risks/Challenges:\n",
    "This field identifies any risks or challenges faced during the patient's care or stay. Possible labels:\n",
    "unknown: Default\n",
    "user_error\n",
    "insurance_issue: The feedback mentions an issue with health insurance.\n",
    "waiting_time: Anything about a long wait time is mentioned.\n",
    "safety_resources\n",
    "public_concern\n",
    "safety_concern: The feedback mentions a safety concern in the hospital.\n",
    "public_external\n",
    "resources_waiting\n",
    "waiting_external\n",
    "insurance_error\n",
    "safety_waiting\n",
    "safety_user\n",
    "user_waiting\n",
    "\n",
    "Actions/Strategies:\n",
    "This field details any actions or strategies employed to address the patient's needs or the circumstances of their care. Possible labels:\n",
    "unknown: Default\n",
    "communication_staff: The feedback indicates that communication with hospital staff helped them solve their issue.\n",
    "communication_interaction\n",
    "use_resources: The feedback indicates that the hospital was resourceful in treating them.\n",
    "\n",
    "Facilitators:\n",
    "This field covers the resources or factors that facilitated the patient's care positively. Possible labels:\n",
    "unknown: Default\n",
    "resources_caring: The feedback indicates that the staff were kind or caring in the service provided.\n",
    "resources_documentation: The feedback specifically mentions staff using documentation or records.\n",
    "quick_response: The patient was pleased with a short wait time in the feedback.\n",
    "\n",
    "Visit Rating:\n",
    "Return a number from 1 to 5 depending on how well the patient's visit went according to the feedback.\n",
    "1: Worst Treatment\n",
    "2: Bad Treatment\n",
    "3. Mediocre Treatment\n",
    "4. Good Treatment\n",
    "5. Best Treatment\n",
    "unknown: Default, if a score cannot be inferred from feedback.\n",
    "\n",
    "<|eot_id|>\n",
    "'''\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples_list,\n",
    "    prefix=sys_prompt,\n",
    "    suffix='<|start_header_id|>user<|end_header_id|>Patient Feedback: {comment}\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n',\n",
    "    input_variables=[\"comment\"],\n",
    "    partial_variables={}\n",
    ")\n",
    "\n",
    "sys_prompt = prompt.format(comment='hospital')\n",
    "\n",
    "\n",
    "with open(\"prompt.txt\", \"w\") as text_file:\n",
    "    text_file.write(sys_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the returned grammar\n",
    "def parse_data(output):\n",
    "    lines = output.strip().split('\\n')\n",
    "    data = {}\n",
    "\n",
    "    for line in lines:\n",
    "        if ': ' in line:\n",
    "            field, label = line.split(': ', 1)\n",
    "            data[field] = [label]  # Use a list to be compatible with DataFrame\n",
    "    \n",
    "    # Create a DataFrame from the dictionary\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0:\n",
      "Patient Feedback:    [person_name] x  was nice and he listened to all my .   concerns and answered all my questions and he took the time to explain what I did not understand...\n",
      "Expectations Met: yes\n",
      "Trust in Staff: yes\n",
      "Feeling of Safety: unknown\n",
      "Positive Experience: yes\n",
      "Dirty: unknown\n",
      "Risks/Challenges: user_error\n",
      "Actions/Strategies: unknown\n",
      "Facilitators: resources_caring\n",
      "Visit Rating: 1\n",
      "\n",
      "\n",
      "row 1:\n",
      "Patient Feedback:    They treated me exceptionally well, and in exactly the way I needed. I was extremely dehydrated after a night of stomach illness so bad that I couldn't keep down water. Extreme vomiting and diarrhea...   I knew I needed an IV unit to help me get back in shape and they readily agreed, and suggested an anti-nausea medication I hadn't considered before...   Some quick tests were able to show it wasn't [person name] or the flu. Once I was rehydrated and able to hold down a [person_name], they said I was good to go and helped me find the exit. ..   Excellent staff all around!\n",
      "Expectations Met: yes\n",
      "Trust in Staff: yes\n",
      "Feeling of Safety: yes\n",
      "Positive Experience: yes\n",
      "Dirty: unknown\n",
      "Risks/Challenges: user_error\n",
      "Actions/Strategies: unknown\n",
      "Facilitators: resources_caring\n",
      "Visit Rating: 5\n",
      "\n",
      "\n",
      "row 2:\n",
      "Patient Feedback:  * your wait time was just extremely long. Six hours in the emergency room it was just way too long and I spent a total of four and half hours just waiting for someone to do anything. Did an MRI, did an [person_name], didn't talk to the doctor. The overall whole time was extremely bad, I mean other than that, I'm alright.\n",
      "Expectations Met: no\n",
      "Trust in Staff: unknown\n",
      "Feeling of Safety: unknown\n",
      "Positive Experience: no\n",
      "Dirty: unknown\n",
      "Risks/Challenges: waiting_time\n",
      "Actions/Strategies: communication_staff\n",
      "Facilitators: resources_caring\n",
      "Visit Rating: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m# Process the batch\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     batch_results \u001b[39m=\u001b[39m llm\u001b[39m.\u001b[39;49mbatch(batch_prompts)\n\u001b[1;32m     20\u001b[0m     \u001b[39mfor\u001b[39;00m index, result \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(batch\u001b[39m.\u001b[39mindex, batch_results):     \n\u001b[1;32m     21\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/langchain_core/language_models/llms.py:327\u001b[0m, in \u001b[0;36mBaseLLM.batch\u001b[0;34m(self, inputs, config, return_exceptions, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m max_concurrency \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         llm_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    328\u001b[0m             [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m \u001b[39minput\u001b[39;49m \u001b[39min\u001b[39;49;00m inputs],\n\u001b[1;32m    329\u001b[0m             callbacks\u001b[39m=\u001b[39;49m[c\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m c \u001b[39min\u001b[39;49;00m config],\n\u001b[1;32m    330\u001b[0m             tags\u001b[39m=\u001b[39;49m[c\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m c \u001b[39min\u001b[39;49;00m config],\n\u001b[1;32m    331\u001b[0m             metadata\u001b[39m=\u001b[39;49m[c\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m c \u001b[39min\u001b[39;49;00m config],\n\u001b[1;32m    332\u001b[0m             run_name\u001b[39m=\u001b[39;49m[c\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m c \u001b[39min\u001b[39;49;00m config],\n\u001b[1;32m    333\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m         \u001b[39mreturn\u001b[39;00m [g[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m llm_result\u001b[39m.\u001b[39mgenerations]\n\u001b[1;32m    336\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m get_llm_cache() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    804\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    805\u001b[0m     )\n\u001b[1;32m    806\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e, response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    658\u001b[0m                 prompts,\n\u001b[1;32m    659\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    660\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    662\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    663\u001b[0m             )\n\u001b[1;32m    664\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/langchain_core/language_models/llms.py:1317\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1315\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m   1316\u001b[0m     text \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1317\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1318\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1319\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(prompt, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1320\u001b[0m     )\n\u001b[1;32m   1321\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[1;32m   1322\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "Cell \u001b[0;32mIn[1], line 64\u001b[0m, in \u001b[0;36mCustomLLM._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mstop kwargs are not permitted.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m payload \u001b[39m=\u001b[39m {\n\u001b[1;32m     58\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m: prompt,\n\u001b[1;32m     59\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtemperature\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0.15\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgrammar\u001b[39m\u001b[39m\"\u001b[39m: grammar\n\u001b[1;32m     63\u001b[0m }\n\u001b[0;32m---> 64\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mpost(\u001b[39m\"\u001b[39;49m\u001b[39mhttp://localhost:8080/completion\u001b[39;49m\u001b[39m\"\u001b[39;49m, json\u001b[39m=\u001b[39;49mpayload)\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    794\u001b[0m     conn,\n\u001b[1;32m    795\u001b[0m     method,\n\u001b[1;32m    796\u001b[0m     url,\n\u001b[1;32m    797\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    798\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    799\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    800\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    801\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    802\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    803\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    804\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    805\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    806\u001b[0m )\n\u001b[1;32m    808\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    538\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/site-packages/urllib3/connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    465\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    468\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/train_qual/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_d = pd.DataFrame().reindex_like(new_data)\n",
    "new_d = new_d.head(0)\n",
    "\n",
    "\n",
    "# Perform Analysis\n",
    "batch_size = 1  # Adjust batch size according to your requirements and limitations\n",
    "batches = [new_data[i:i + batch_size]\n",
    "            for i in range(0, new_data.shape[0], batch_size)]\n",
    "\n",
    "for batch in batches:\n",
    "    # Create a batched prompt for processing\n",
    "    batch_prompts = [prompt.format(comment=(row[data_column]).strip())\n",
    "                        for index, row in batch.iterrows()]\n",
    "    batch_comments = [row[data_column]\n",
    "                        for index, row in batch.iterrows()]\n",
    "\n",
    "    # Process the batch\n",
    "    try:\n",
    "        batch_results = llm.batch(batch_prompts)\n",
    "        for index, result in zip(batch.index, batch_results):     \n",
    "            try:\n",
    "                \n",
    "                new_row = parse_data(result)\n",
    "\n",
    "                print(f\"row {index}:\")\n",
    "                print(\"Patient Feedback: \" + batch_comments[0])\n",
    "                print(result)\n",
    "                print(\"\")\n",
    "                new_row[data_column] = batch_comments[0]\n",
    "                \n",
    "                new_d = pd.concat([new_d, new_row], ignore_index=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Error analyzing row {index}: {e}')\n",
    "    except Exception as e:\n",
    "        print(f'Error processing batch: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d.replace('', 'Unknown')\n",
    "new_d.to_csv('sample_70b.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
